[![DOI](https://zenodo.org/badge/78084425.svg)](https://zenodo.org/badge/latestdoi/78084425)
[![Documentation Status](https://readthedocs.org/projects/hybrid-vocal-classifier/badge/?version=latest)](http://hybrid-vocal-classifier.readthedocs.io/en/latest/?badge=latest)

# hybrid-vocal-classifier
Python package that automates segmenting and labeling vocalizations. 
The main application of the package is to birdsong, but the long-term goal is to make it easy to segment and label any vocalization.

[![Project Status: Inactive â€“ The project has reached a stable, usable state but is no longer being actively developed; support/maintenance will be provided as time allows.](https://www.repostatus.org/badges/latest/inactive.svg)](https://www.repostatus.org/#inactive)
Currently this project is inactive. Please see https://github.com/NickleDave/vak for an actively developed library with similar goals (but better algorithms, such as https://github.com/yardencsGitHub/tweetynet). This project may incorporate lessons learned from development of `tweetynet` and `vak` at a future point.

website: http://hybrid-vocal-classifier.readthedocs.io

BSD License.

hybrid-vocal-classifier was originally developed in [the Sober lab](https://scholarblogs.emory.edu/soberlab/)
